{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1\n",
      "True\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "c:\\Users\\NilsWindows\\Desktop\\research2.0\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.1\n",
      "Mon Nov 10 12:49:34 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 539.56                 Driver Version: 539.56       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla P4                     TCC   | 00000000:06:10.0 Off |                    0 |\n",
      "| N/A   32C    P8               6W /  75W |      8MiB /  7680MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Wed_Feb__8_05:53:42_Coordinated_Universal_Time_2023\n",
      "Cuda compilation tools, release 12.1, V12.1.66\n",
      "Build cuda_12.1.r12.1/compiler.32415258_0\n"
     ]
    }
   ],
   "source": [
    "#check CUDA und d3rlpy Installation\n",
    "!nvidia-smi\n",
    "!nvcc --version\n",
    "import torch \n",
    "print(torch.version.cuda)  # sollte '12.2' oder ähnlich anzeigen\n",
    "print(torch.cuda.is_available())  # sollte True sein\n",
    "print(torch.cuda.current_device())  # sollte 0 sein, wenn eine GPU verfügbar ist\n",
    "import d3rlpy\n",
    "print(d3rlpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-10 12:49.55 [info     ] Signatures have been automatically determined. action_signature=Signature(dtype=[dtype('float64')], shape=[(4,)]) observation_signature=Signature(dtype=[dtype('float64')], shape=[(100,)]) reward_signature=Signature(dtype=[dtype('float64')], shape=[(1,)])\n",
      "2025-11-10 12:49.55 [info     ] Action-space has been automatically determined. action_space=<ActionSpace.CONTINUOUS: 1>\n",
      "2025-11-10 12:49.55 [info     ] Action size has been automatically determined. action_size=4\n",
      "2025-11-10 12:49.56 [info     ] dataset info                   dataset_info=DatasetInfo(observation_signature=Signature(dtype=[dtype('float64')], shape=[(100,)]), action_signature=Signature(dtype=[dtype('float64')], shape=[(4,)]), reward_signature=Signature(dtype=[dtype('float64')], shape=[(1,)]), action_space=<ActionSpace.CONTINUOUS: 1>, action_size=4)\n",
      "2025-11-10 12:49.56 [warning  ] Skip building models since they're already built.\n",
      "2025-11-10 12:49.57 [info     ] Directory is created at d3rlpy_logs\\SAC_20251110124957\n",
      "2025-11-10 12:49.57 [info     ] Parameters                     params={'observation_shape': [100], 'action_size': 4, 'config': {'type': 'sac', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'temp_learning_rate': 0.0003, 'actor_optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'critic_optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'temp_optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'actor_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'critic_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'tau': 0.005, 'n_critics': 2, 'initial_temperature': 1.0}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 10000/10000 [04:40<00:00, 35.69it/s, critic_loss=8.45, actor_loss=-93.2, temp=1.24, temp_loss=-1.66]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-10 12:54.38 [info     ] SAC_20251110124957: epoch=1 step=10000 epoch=1 metrics={'time_sample_batch': 0.006094509816169739, 'time_algorithm_update': 0.021029426193237305, 'critic_loss': 8.500654422685503, 'actor_loss': -93.52499094626903, 'temp': 1.2426019729018212, 'temp_loss': -1.6740991617945022, 'time_step': 0.027544213247299193, 'td_error': 5650.247548962815} step=10000\n",
      "2025-11-10 12:54.38 [info     ] Model parameters are saved to d3rlpy_logs\\SAC_20251110124957\\model_10000.d3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NilsWindows\\Desktop\\research2.0\\.venv\\lib\\site-packages\\d3rlpy\\torch_utility.py:431: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  chkpt = torch.load(f, map_location=map_location(self._device))\n"
     ]
    }
   ],
   "source": [
    "import d3rlpy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# vector observation\n",
    "# 1000 steps of observations with shape of (100,)\n",
    "observations = np.random.random((1000, 100))\n",
    "\n",
    "# 1000 steps of actions with shape of (4,)\n",
    "actions = np.random.random((1000, 4))\n",
    "\n",
    "# 1000 steps of rewards\n",
    "rewards = np.random.random(1000)\n",
    "\n",
    "# 1000 steps of terminal flags\n",
    "terminals = np.random.randint(2, size=1000)\n",
    "\n",
    "dataset = d3rlpy.dataset.MDPDataset(\n",
    "    observations=observations,\n",
    "    actions=actions,\n",
    "    rewards=rewards,\n",
    "    terminals=terminals,\n",
    ")\n",
    "\n",
    "\n",
    "# if you don't use GPU, set device=None instead.\n",
    "sac = d3rlpy.algos.SACConfig().create(device='cuda:0')\n",
    "\n",
    "# initialize neural networks with the given observation shape and action size.\n",
    "# this is not necessary when you directly call fit or fit_online method.\n",
    "sac.build_with_dataset(dataset)\n",
    "# calculate metrics with training dataset\n",
    "td_error_evaluator = d3rlpy.metrics.TDErrorEvaluator(episodes=dataset.episodes)\n",
    "\n",
    "# evaluate algorithm on the environment\n",
    "#rewards = env_evaluator(sac, dataset=None)\n",
    "\n",
    "sac.fit(\n",
    "    dataset,\n",
    "    n_steps=10000,\n",
    "    evaluators={\n",
    "        'td_error': td_error_evaluator,\n",
    "    }\n",
    ")\n",
    "\n",
    "# get first observation from the dataset\n",
    "observation = observations[0]\n",
    "\n",
    "# return actions based on the greedy-policy\n",
    "action = sac.predict(np.expand_dims(observation, axis=0))\n",
    "\n",
    "# estimate action-values\n",
    "value = sac.predict_value(np.expand_dims(observation, axis=0), action)\n",
    "\n",
    "# save full parameters and configurations in a single file.\n",
    "sac.save('sac.d3')\n",
    "# load full parameters and build algorithm\n",
    "sac2 = d3rlpy.load_learnable(\"sac.d3\")\n",
    "\n",
    "# save full parameters only\n",
    "sac.save_model('sac.pt')\n",
    "\n",
    "# save the greedy-policy as TorchScript\n",
    "sac.save_policy('policy.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
